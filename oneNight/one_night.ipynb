{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2dce9ef",
   "metadata": {},
   "source": [
    "## éš”æ—¥æ²–ç¸¾æ•ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ad8ad",
   "metadata": {},
   "source": [
    "### è£½ä½œæ¦œå–® by api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4995ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version : 20250925\n",
      "ä»Šå¤©æ˜¯ 2025-09-25ï¼Œå°è‚¡äº¤æ˜“æ—¥ï¼Œé–‹å§‹åŸ·è¡Œç¨‹å¼ã€‚\n",
      "è¡Œæƒ…å…ƒä»¶åˆå§‹åŒ–æˆåŠŸï¼\n",
      "æ­£åœ¨æŠ“å–ä¸Šå¸‚åŠä¸Šæ«ƒæ¼²å¹…æ¦œè³‡æ–™...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from fubon_neo.sdk import FubonSDK\n",
    "import pandas_market_calendars as mcal\n",
    "\n",
    "# version yyyymmdd\n",
    "__version__ = \"20250925\"\n",
    "\n",
    "# --- è¨­å®šå€ ---\n",
    "# æ ¹æ“šç¨‹å¼é‹è¡Œç’°å¢ƒï¼Œå‹•æ…‹æ±ºå®šè¨­å®šæª”è·¯å¾‘\n",
    "if getattr(sys, 'frozen', False):\n",
    "    # --- æƒ…å¢ƒ 1: éƒ¨ç½² / åˆ†äº« (æœ€ç°¡æ½”çš„æ–¹å¼) ---\n",
    "    base_path = os.path.dirname(sys.executable)\n",
    "elif 'ipykernel' in sys.modules:\n",
    "    # --- æƒ…å¢ƒ 2: ipynb è…³æœ¬ (Jupyter ç’°å¢ƒ) ---\n",
    "    # åœ¨ Jupyter ä¸­ï¼Œos.getcwd() é€šå¸¸æ˜¯è…³æœ¬æ‰€åœ¨çš„ç›®éŒ„\n",
    "    base_path = os.getcwd()\n",
    "else:\n",
    "    # --- æƒ…å¢ƒ 3: .py è…³æœ¬ (ä¸€èˆ¬ Python ç’°å¢ƒ) ---\n",
    "    # .py è…³æœ¬æœƒä½¿ç”¨ __file__ è®Šæ•¸ä¾†å–å¾—è‡ªèº«è·¯å¾‘\n",
    "    base_path = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# æ¯æ—¥æ¦œå–® è¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘\n",
    "# å‡è¨­ out_oneNight è³‡æ–™å¤¾ä¹Ÿåœ¨ .py/.ipynb/.exe æ‰€åœ¨çš„ç›®éŒ„\n",
    "OUTPUT_DIRECTORY = os.path.join(base_path, 'out_oneNight')\n",
    "\n",
    "# è¨­å®šæª”è·¯å¾‘\n",
    "# config.json åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„ (oneNight çš„ä¸Šå±¤)\n",
    "project_root = os.path.dirname(base_path)\n",
    "config_path = os.path.join(project_root, 'config', 'config.json')\n",
    "\n",
    "# --- è¨­å®šçµæŸ ---\n",
    "\n",
    "# --- åˆ¤æ–·ä»Šå¤©æ˜¯å¦ç‚ºäº¤æ˜“æ—¥ ---\n",
    "def is_trading_day():\n",
    "    \"\"\"åˆ¤æ–·ä»Šå¤©æ˜¯å¦ç‚ºå°ç£è‚¡å¸‚çš„äº¤æ˜“æ—¥ã€‚\"\"\"\n",
    "    xtai_calendar = mcal.get_calendar('XTAI')\n",
    "    today_dt = datetime.now().date()\n",
    "\n",
    "    # å–å¾—ä»Šå¤©æ˜¯å¦ç‚ºäº¤æ˜“æ—¥çš„åˆ—è¡¨\n",
    "    valid_trading_days = xtai_calendar.valid_days(start_date=today_dt, end_date=today_dt)\n",
    "\n",
    "    # å°‡åˆ—è¡¨ä¸­çš„æ—¥æœŸè½‰æ›ç‚ºä¸å«æ™‚å€çš„æ—¥æœŸ (remove timezone)\n",
    "    valid_trading_days_naive = valid_trading_days.tz_convert(None)\n",
    "\n",
    "    # å°‡ä»Šå¤©çš„æ—¥æœŸè½‰æ›æˆ datetime object\n",
    "    today_datetime = pd.to_datetime(today_dt)\n",
    "\n",
    "    # æª¢æŸ¥ä»Šå¤©æ˜¯å¦åœ¨å°ç£è‚¡å¸‚çš„äº¤æ˜“æ—¥åˆ—è¡¨ä¸­\n",
    "    return today_datetime in valid_trading_days_naive\n",
    "\n",
    "def fetch_and_select_stocks():\n",
    "    \"\"\"å¾ API æŠ“å–æ¼²å¹…æ¦œè³‡æ–™ï¼Œä¸¦æ ¹æ“šæ¢ä»¶ç¯©é¸è‚¡ç¥¨ã€‚\"\"\"\n",
    "    try:\n",
    "        print(\"æ­£åœ¨æŠ“å–ä¸Šå¸‚åŠä¸Šæ«ƒæ¼²å¹…æ¦œè³‡æ–™...\")\n",
    "        # å–å¾—ä¸Šå¸‚æ¼²å¹…æ¦œ(COMMONSTOCKç‚ºä¸€èˆ¬è‚¡ç¥¨)\n",
    "        tse_movers = restStock.snapshot.movers(\n",
    "            market='TSE', direction='up', change='percent', type='COMMONSTOCK', gte=5\n",
    "        )['data']\n",
    "        # å–å¾—ä¸Šæ«ƒæ¼²å¹…æ¦œ(COMMONSTOCKç‚ºä¸€èˆ¬è‚¡ç¥¨)\n",
    "        otc_movers = restStock.snapshot.movers(\n",
    "            market='OTC', direction='up', change='percent', type='COMMONSTOCK', gte=5\n",
    "        )['data']\n",
    "        \n",
    "        # åˆä½µä¸Šå¸‚æ«ƒè³‡æ–™ä¸¦è½‰æ›æˆ DataFrame\n",
    "        all_movers = tse_movers + otc_movers\n",
    "        df = pd.DataFrame(all_movers)\n",
    "        \n",
    "        # 2. ä»¥æ¼²å¹…æ¬„ä½ (change_percent) é€²è¡Œé™å†ªæ’åº\n",
    "        df.sort_values(by='changePercent', ascending=False, inplace=True)\n",
    "        # inplace=True æœƒç›´æ¥ä¿®æ”¹ DataFrameï¼Œè€Œä¸æ˜¯å›å‚³ä¸€å€‹æ–°çš„\n",
    "    except Exception as e:\n",
    "        print(f\"å¾ API å–å¾—è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # API æ¬„ä½åç¨±èˆ‡ä½ çš„ Excel å ±è¡¨ä¸ç¬¦ï¼Œéœ€è¦é‡æ–°å‘½å\n",
    "    df.rename(columns={\n",
    "        'symbol': 'è‚¡è™Ÿ',\n",
    "        'name': 'åç¨±',\n",
    "        'changePercent': 'å¹…åº¦ï¼…',\n",
    "        'closePrice': 'æˆäº¤',\n",
    "        'tradeVolume': 'æˆäº¤é‡',\n",
    "        'tradeValue': 'æˆäº¤å€¼'\n",
    "    }, inplace=True)\n",
    "\n",
    "    condition_gain = df['å¹…åº¦ï¼…'] >= 5\n",
    "    condition_volume = df['æˆäº¤é‡'] >= 1500\n",
    "    condition_value = (df['æˆäº¤é‡'] * 1000) * df['æˆäº¤'] >= 90000000\n",
    "    # 'ç”¢æ¥­åˆ¥'ä¸ç”¨ç¯©é¸ \"ETF|å…¬å¸å‚µ\" äº†ï¼Œå·²ç¶“ä½¿ç”¨ type = COMMONSTOCK ä¸€èˆ¬è‚¡ç¥¨\n",
    "    \n",
    "    selected_df = df[condition_gain & condition_volume & condition_value].copy()\n",
    "    \n",
    "    # è¨˜éŒ„æ”¶ç›¤åƒ¹æ˜¯å¦é«˜æ–¼ç•¶æ—¥å‡åƒ¹\n",
    "    selected_df['ç«™ä¸Šå‡åƒ¹'] = ''\n",
    "    for index, row in selected_df.iterrows():\n",
    "        symbol = row['è‚¡è™Ÿ']\n",
    "        try:\n",
    "            day_data = restStock.intraday.quote(symbol=symbol)\n",
    "            \n",
    "            if not day_data:\n",
    "                selected_df.loc[index, 'ç«™ä¸Šå‡åƒ¹'] = 'ç„¡è³‡æ–™'\n",
    "                continue\n",
    "\n",
    "            latest_close = day_data['closePrice']\n",
    "            latest_vwap = day_data['avgPrice']\n",
    "            \n",
    "            is_above_vwap = latest_close > latest_vwap  # ç«™ä¸Šå‡åƒ¹\n",
    "            \n",
    "            selected_df.loc[index, 'ç«™ä¸Šå‡åƒ¹'] = 'æ˜¯' if is_above_vwap else 'å¦'\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" > è­¦å‘Šï¼šåˆ¤æ–· {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "            selected_df.loc[index, 'ç«™ä¸Šå‡åƒ¹'] = 'éŒ¯èª¤'    \n",
    "\n",
    "    return selected_df\n",
    "\n",
    "def save_daily_selection(selected_stocks, output_dir):\n",
    "    if selected_stocks.empty:\n",
    "        print(\"ä»Šæ—¥æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ã€‚\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"å»ºç«‹æ–°è³‡æ–™å¤¾: {output_dir}\")\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    now = datetime.now()\n",
    "    today_str_ymd = now.strftime('%Y-%m-%d')\n",
    "    output_df = pd.DataFrame({\n",
    "        'é¸è‚¡æ—¥': today_str_ymd,\n",
    "        'è‚¡ç¥¨ä»£è™Ÿ': selected_stocks['è‚¡è™Ÿ'].astype(int),\n",
    "        'è‚¡ç¥¨åç¨±': selected_stocks['åç¨±'],\n",
    "        'ç•¶æ—¥æ”¶ç›¤åƒ¹': selected_stocks['æˆäº¤'],\n",
    "        'ç•¶æ—¥æ¼²å¹…%': selected_stocks['å¹…åº¦ï¼…'],\n",
    "        'ç«™ä¸Šå‡åƒ¹': selected_stocks['ç«™ä¸Šå‡åƒ¹'],\n",
    "        'éš”æ—¥é–‹ç›¤åƒ¹': '', # é ç•™æ¬„ä½\n",
    "        'éš”æ—¥æœ€é«˜åƒ¹': '', # é ç•™æ¬„ä½\n",
    "        'éš”æ—¥æœ€ä½åƒ¹': '', # é ç•™æ¬„ä½\n",
    "        'éš”æ—¥æ”¶ç›¤åƒ¹': '', # é ç•™æ¬„ä½\n",
    "        'è³£å‡ºåƒ¹æ ¼': '',\n",
    "        'åœåˆ©/åœæ': '',\n",
    "        'æç›Š%': ''\n",
    "    })\n",
    "    \n",
    "    # å¦‚æœåœ¨ä¸‹åˆ 1:30 ä¹‹å‰åŸ·è¡Œï¼Œå‰‡åŠ ä¸Š \"_ä¸­åˆ\"\n",
    "    today_str_filename = now.strftime('%Y%m%d')\n",
    "    if now.hour <= 13 and now.minute <= 30:\n",
    "        output_filename = f\"{today_str_filename}_æ¼²å¹…_ä¸­åˆ.xlsx\"\n",
    "    else:\n",
    "        output_filename = f\"{today_str_filename}_æ¼²å¹….xlsx\"\n",
    "        \n",
    "        # 2. å‚™ä»½æª”æ¡ˆï¼šç”¨æ–¼è¨ˆç®— -1.5% åœæçš„å°ˆå±¬ exe\n",
    "        output_filename_15 = f\"{today_str_filename}_æ¼²å¹…_15.xlsx\"\n",
    "        output_filepath_15 = os.path.join(output_dir, output_filename_15)\n",
    "        output_df.to_excel(output_filepath_15, index=False)\n",
    "    output_filepath = os.path.join(output_dir, output_filename)\n",
    "    output_df.to_excel(output_filepath, index=False)\n",
    "    print(f\"æ¦œå–®å·²å„²å­˜è‡³: {output_filepath}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"version : {__version__}\")\n",
    "    if not is_trading_day():\n",
    "        print(f\"ä»Šå¤©æ˜¯ {datetime.now().date().strftime('%Y-%m-%d')}ï¼Œéå°è‚¡äº¤æ˜“æ—¥ï¼Œç¨‹å¼çµæŸã€‚\")\n",
    "    else:\n",
    "        print(f\"ä»Šå¤©æ˜¯ {datetime.now().date().strftime('%Y-%m-%d')}ï¼Œå°è‚¡äº¤æ˜“æ—¥ï¼Œé–‹å§‹åŸ·è¡Œç¨‹å¼ã€‚\")\n",
    "\n",
    "        # --- ç™»å…¥ ---\n",
    "        try:\n",
    "            with open(config_path, 'r', encoding='utf-8') as f:\n",
    "                config = json.load(f)\n",
    "            \n",
    "            # å¾è¨­å®šæª”ä¸­å–å¾—ç™»å…¥è³‡è¨Š\n",
    "            fubon_config = config['fubon_api']\n",
    "            user_id = fubon_config['id']\n",
    "            user_password = fubon_config['password']\n",
    "            cert_path = fubon_config['cert_path']\n",
    "            cert_pass = fubon_config['cert_pass']\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(\"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° config.json è¨­å®šæª”ï¼\")\n",
    "            exit()\n",
    "        except KeyError:\n",
    "            print(\"éŒ¯èª¤ï¼šconfig.json æª”æ¡ˆä¸­çš„ key ä¸æ­£ç¢ºï¼\")\n",
    "            exit()\n",
    "\n",
    "        sdk = None\n",
    "        # é€£çµ API Server\n",
    "        sdk = FubonSDK()\n",
    "\n",
    "        accounts = sdk.login(user_id, user_password, cert_path, cert_pass)\n",
    "\n",
    "        sdk.init_realtime() # å»ºç«‹è¡Œæƒ…å…ƒä»¶é€£ç·š\n",
    "        print(\"è¡Œæƒ…å…ƒä»¶åˆå§‹åŒ–æˆåŠŸï¼\")\n",
    "        \n",
    "        restStock = sdk.marketdata.rest_client.stock\n",
    "\n",
    "        selected_stocks_today = fetch_and_select_stocks()\n",
    "        \n",
    "        # å„²å­˜çµæœ\n",
    "        save_daily_selection(selected_stocks_today, OUTPUT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0764fa",
   "metadata": {},
   "source": [
    "### è¨ˆç®—ç¸¾æ•ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7cd1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version : 20250925\n",
      "valid_trading_days_naive:  DatetimeIndex(['2025-09-29'], dtype='datetime64[ns]', freq='C')\n",
      "ä»Šå¤©æ˜¯ 2025-09-29ï¼Œå°è‚¡äº¤æ˜“æ—¥ï¼Œé–‹å§‹åŸ·è¡Œç¨‹å¼ã€‚\n",
      "Fubon SDK åˆå§‹åŒ–å®Œç•¢ï¼\n",
      "æª”æ¡ˆä¸­æ‰€æœ‰è‚¡ç¥¨çš†å·²è¨ˆç®—éç¸¾æ•ˆã€‚\n",
      "\n",
      "ç¸¾æ•ˆè¨ˆç®—å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from openpyxl import load_workbook\n",
    "import pandas_market_calendars as mcal\n",
    "import sys\n",
    "\n",
    "# åŒ¯å…¥ SDK Library\n",
    "from fubon_neo.sdk import FubonSDK, Order\n",
    "from fubon_neo.constant import TimeInForce, OrderType, PriceType, MarketType, BSAction\n",
    "\n",
    "# version yyyymmdd\n",
    "__version__ = \"20250925\"\n",
    "\n",
    "STOP_PROFIT_PERCENT = 1.5 # è¨­å®šåœåˆ©é»ç‚º 1.5%\n",
    "STOP_LOSS_PERCENT = -2.0  # è¨­å®šåœæé»ç‚º -2.0%\n",
    "TRANSACTION_COST_PERCENT = 0.6 # äº¤æ˜“æˆæœ¬\n",
    "\n",
    "# --- è¨­å®šå€ ---\n",
    "# æ ¹æ“šç¨‹å¼é‹è¡Œç’°å¢ƒï¼Œå‹•æ…‹æ±ºå®šè¨­å®šæª”è·¯å¾‘\n",
    "if getattr(sys, 'frozen', False):\n",
    "    # --- æƒ…å¢ƒ 1: éƒ¨ç½² / åˆ†äº« (æœ€ç°¡æ½”çš„æ–¹å¼) ---\n",
    "    base_path = os.path.dirname(sys.executable)\n",
    "elif 'ipykernel' in sys.modules:\n",
    "    # --- æƒ…å¢ƒ 2: ipynb è…³æœ¬ (Jupyter ç’°å¢ƒ) ---\n",
    "    # åœ¨ Jupyter ä¸­ï¼Œos.getcwd() é€šå¸¸æ˜¯è…³æœ¬æ‰€åœ¨çš„ç›®éŒ„\n",
    "    base_path = os.getcwd()\n",
    "else:\n",
    "    # --- æƒ…å¢ƒ 3: .py è…³æœ¬ (ä¸€èˆ¬ Python ç’°å¢ƒ) ---\n",
    "    # .py è…³æœ¬æœƒä½¿ç”¨ __file__ è®Šæ•¸ä¾†å–å¾—è‡ªèº«è·¯å¾‘\n",
    "    base_path = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# æ¯æ—¥æ¦œå–® è¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘\n",
    "# å‡è¨­ out_oneNight è³‡æ–™å¤¾ä¹Ÿåœ¨ .py/.ipynb/.exe æ‰€åœ¨çš„ç›®éŒ„\n",
    "OUTPUT_DIRECTORY = os.path.join(base_path, 'out_oneNight')\n",
    "\n",
    "# è¨­å®šæª”è·¯å¾‘\n",
    "# config.json åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„ (oneNight çš„ä¸Šå±¤)\n",
    "project_root = os.path.dirname(base_path)\n",
    "config_path = os.path.join(project_root, 'config', 'config.json')\n",
    "\n",
    "# å°ç£è­‰åˆ¸äº¤æ˜“æ‰€ (XTAI) çš„æ—¥æ›†\n",
    "xtai_calendar = mcal.get_calendar('XTAI')\n",
    "# --- è¨­å®šçµæŸ ---\n",
    "\n",
    "# --- åˆ¤æ–·ä»Šå¤©æ˜¯å¦ç‚ºäº¤æ˜“æ—¥ ---\n",
    "def is_trading_day():\n",
    "    \"\"\"åˆ¤æ–·ä»Šå¤©æ˜¯å¦ç‚ºå°ç£è‚¡å¸‚çš„äº¤æ˜“æ—¥ã€‚\"\"\"\n",
    "    today_dt = datetime.now().date()\n",
    "\n",
    "    # å–å¾—ä»Šå¤©æ˜¯å¦ç‚ºäº¤æ˜“æ—¥çš„åˆ—è¡¨\n",
    "    valid_trading_days = xtai_calendar.valid_days(start_date=today_dt, end_date=today_dt)\n",
    "\n",
    "    # å°‡åˆ—è¡¨ä¸­çš„æ—¥æœŸè½‰æ›ç‚ºä¸å«æ™‚å€çš„æ—¥æœŸ (remove timezone)\n",
    "    valid_trading_days_naive = valid_trading_days.tz_convert(None)\n",
    "    print(\"valid_trading_days_naive: \", valid_trading_days_naive)\n",
    "\n",
    "    # å°‡ä»Šå¤©çš„æ—¥æœŸè½‰æ›æˆ datetime object\n",
    "    today_datetime = pd.to_datetime(today_dt)\n",
    "\n",
    "    # æª¢æŸ¥ä»Šå¤©æ˜¯å¦åœ¨å°ç£è‚¡å¸‚çš„äº¤æ˜“æ—¥åˆ—è¡¨ä¸­\n",
    "    return today_datetime in valid_trading_days_naive\n",
    "\n",
    "def get_intraday_minute_kbars(stock_id):\n",
    "    \"\"\"\n",
    "    æ¥æ”¶ä¸€å€‹è‚¡ç¥¨ä»£è™Ÿå’Œæ—¥æœŸï¼Œå» API è«‹æ±‚ç•¶å¤©æ‰€æœ‰çš„ 5åˆ†K è³‡æ–™ã€‚\n",
    "\n",
    "    Args:\n",
    "        stock_id (str): è‚¡ç¥¨ä»£è™Ÿï¼Œä¾‹å¦‚ '2330'ã€‚\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: åŒ…å«ç•¶å¤©æ‰€æœ‰åˆ†é˜ K æ£’çš„åˆ—è¡¨ï¼Œ\n",
    "                    å¦‚æœå¤±æ•—å‰‡è¿”å› Noneã€‚\n",
    "    \"\"\"\n",
    "    try:        \n",
    "        reststock = sdk.marketdata.rest_client.stock \n",
    "        candles = reststock.intraday.candles(symbol=stock_id, timeframe=5)\n",
    "        today_kbars = candles.get('data', [])\n",
    "\n",
    "        return today_kbars\n",
    "    except Exception as e:\n",
    "        print(f\"éŒ¯èª¤ï¼šç„¡æ³•å–å¾— {stock_id} çš„åˆ†é˜Kæ£’è³‡æ–™. åŸå› : {e}\")\n",
    "        return None\n",
    "\n",
    "def run_high_precision_backtest(purchase_price, stock_id):\n",
    "    \"\"\"\n",
    "    å–å¾—åˆ†é˜Kæ£’ï¼Œæ¨¡æ“¬ç›¤ä¸­èµ°å‹¢ï¼Œæ‰¾å‡ºæœ€å…ˆè§¸ç™¼çš„äº‹ä»¶ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    take_profit_price = purchase_price * (1 + (STOP_PROFIT_PERCENT / 100))\n",
    "    stop_loss_price = purchase_price * (1 + (STOP_LOSS_PERCENT / 100))\n",
    "\n",
    "    # å–å¾—ç•¶å¤©æ‰€æœ‰çš„åˆ†é˜Kæ£’\n",
    "    minute_kbars = get_intraday_minute_kbars(stock_id)\n",
    "    if not minute_kbars: return None\n",
    "    \n",
    "    # --- å¾åˆ†é˜Kæ£’ä¸­ï¼Œé å…ˆè¨ˆç®—å‡ºç•¶æ—¥çš„å®Œæ•´ OHLC ---\n",
    "    day2_open = minute_kbars[0].get('open', purchase_price)\n",
    "    day2_high = max(k.get('high', 0) for k in minute_kbars)\n",
    "    day2_low = min(k.get('low', float('inf')) for k in minute_kbars)\n",
    "    day2_close = minute_kbars[-1].get('close', purchase_price)\n",
    "    \n",
    "    daily_ohlc_data = {\n",
    "        'open': day2_open,\n",
    "        'high': day2_high,\n",
    "        'low': day2_low,\n",
    "        'close': day2_close\n",
    "    }\n",
    "\n",
    "    # --- åˆ¤æ–·å‡ºå ´é‚è¼¯ ---\n",
    "    result = ''\n",
    "    pnl_percent = 0\n",
    "    sell_price = 0\n",
    "\n",
    "    # æª¢æŸ¥é–‹ç›¤åƒ¹æ˜¯å¦å‘ä¸Šè·³ç©ºç¼ºå£ ç›´æ¥è¶…éåœåˆ©é»ï¼Œä»¥é–‹ç›¤åƒ¹è³£å‡º\n",
    "    if day2_open >= take_profit_price:\n",
    "        result = 'åœåˆ©'\n",
    "        sell_price = day2_open # è³£å‡ºåƒ¹ç‚ºé–‹ç›¤åƒ¹\n",
    "        pnl_percent = (((sell_price - purchase_price) / purchase_price) * 100) - TRANSACTION_COST_PERCENT\n",
    "    else:\n",
    "        # å¦‚æœæ²’æœ‰é–‹ç›¤è·³ç©ºï¼Œæ‰é€²å…¥ç›¤ä¸­æ¨¡æ“¬\n",
    "        for kbar in minute_kbars:\n",
    "            # æª¢æŸ¥é€™æ ¹Kæ£’çš„æœ€ä½åƒ¹ï¼Œæ˜¯å¦\"å…ˆ\"è§¸åŠåœæé» (é¢¨éšªå„ªå…ˆ ç•¶ä½œå…ˆè§¸ç™¼åœæ)\n",
    "            if kbar.get('low', float('inf')) <= stop_loss_price:\n",
    "                result = 'åœæ'\n",
    "                sell_price = stop_loss_price # è³£å‡ºåƒ¹ç‚ºåœæåƒ¹\n",
    "                pnl_percent = STOP_LOSS_PERCENT - TRANSACTION_COST_PERCENT\n",
    "                break\n",
    "            \n",
    "            # å†æª¢æŸ¥é€™æ ¹Kæ£’çš„æœ€é«˜åƒ¹ï¼Œæ˜¯å¦è§¸åŠåœåˆ©é»\n",
    "            if kbar.get('high', 0) >= take_profit_price:\n",
    "                result = 'åœåˆ©'\n",
    "                sell_price = take_profit_price # è³£å‡ºåƒ¹ç‚ºåœåˆ©åƒ¹\n",
    "                pnl_percent = STOP_PROFIT_PERCENT - TRANSACTION_COST_PERCENT\n",
    "                break\n",
    "\n",
    "    # å¦‚æœè¿´åœˆè·‘å®Œï¼Œresult ä¾ç„¶æ˜¯ç©ºçš„ï¼Œä»£è¡¨ç›¤ä¸­éƒ½æ²’è§¸ç™¼\n",
    "    if not result:\n",
    "        sell_price = day2_close # è³£å‡ºåƒ¹ç‚ºæ”¶ç›¤åƒ¹\n",
    "        \n",
    "        pnl_percent = (((sell_price - purchase_price) / purchase_price) * 100) - TRANSACTION_COST_PERCENT\n",
    "        if pnl_percent > 0:\n",
    "            result = 'åœåˆ©'\n",
    "        else:\n",
    "            result = 'åœæ'\n",
    "\n",
    "    return {\n",
    "        'result': result,\n",
    "        'pnl_percent': pnl_percent, \n",
    "        'sell_price': sell_price,\n",
    "        'daily_ohlc': daily_ohlc_data\n",
    "    }\n",
    "\n",
    "def generate_summary_and_save(df, filepath):\n",
    "    \"\"\"\n",
    "    ç›´æ¥ä½¿ç”¨å·²ç®—å¥½çš„ã€Œæç›Š%ã€æ¬„ä½ä¾†è¨ˆç®—ç¸½é‡‘é¡ï¼Œç¢ºä¿é‚è¼¯ä¸€è‡´ã€‚\n",
    "    \"\"\"\n",
    "    # --- è¨­å®šå€ ---\n",
    "    SHARES_PER_TRADE = 1000\n",
    "    COST_FACTOR = 1.006  # å°‡æ‰€æœ‰è²·è³£æˆæœ¬çµ±ä¸€ä¼°ç®—ç‚º 0.6%ï¼Œä¸¦è¨ˆå…¥è²·å…¥æˆæœ¬\n",
    "\n",
    "    # --- 1. ç¯©é¸å‡ºå·²å®Œæˆçš„äº¤æ˜“ ---\n",
    "    completed_trades = df[df['è³£å‡ºåƒ¹æ ¼'].notna()].copy()\n",
    "\n",
    "    if completed_trades.empty:\n",
    "        print(\"æ²’æœ‰å·²å®Œæˆçš„äº¤æ˜“ï¼Œç„¡æ³•ç”¢ç”Ÿç¸¾æ•ˆå ±å‘Šã€‚\")\n",
    "        df.to_excel(filepath, index=False)\n",
    "        return\n",
    "\n",
    "    # --- 2. ç”¨åƒ¹æ ¼é€²è¡ŒåŠ ç¸½è¨ˆç®— ---\n",
    "    \n",
    "    # è¨ˆç®—è²·å…¥è‚¡ç¥¨çš„ç¸½åƒ¹å€¼ (æœªè¨ˆè²»ç”¨)\n",
    "    total_purchase_value = completed_trades['ç•¶æ—¥æ”¶ç›¤åƒ¹'].sum() * SHARES_PER_TRADE\n",
    "    \n",
    "    # è¨ˆç®—è³£å‡ºè‚¡ç¥¨çš„ç¸½åƒ¹å€¼ (æœªè¨ˆè²»ç”¨)\n",
    "    total_sell_value = completed_trades['è³£å‡ºåƒ¹æ ¼'].sum() * SHARES_PER_TRADE\n",
    "\n",
    "    # ç¸½æŠ•å…¥æˆæœ¬ (å¤§æˆæœ¬)ï¼Œ*1.006\n",
    "    total_investment_cost = total_purchase_value * COST_FACTOR\n",
    "    \n",
    "    # ç¸½ç›ˆè™§ (å…ƒ)ï¼šç¸½è³£å‡ºæ”¶å…¥ - ç¸½æŠ•å…¥æˆæœ¬\n",
    "    total_net_profit = total_sell_value - total_investment_cost\n",
    "    \n",
    "    # ç¸½ç¸¾æ•ˆ ROI (%)\n",
    "    total_roi = (total_net_profit / total_investment_cost) * 100 if total_investment_cost > 0 else 0\n",
    "\n",
    "    # --- 3. è¨ˆç®—åœåˆ©/åœææ¬¡æ•¸èˆ‡å‹ç‡ ---\n",
    "    total_trades = len(completed_trades)\n",
    "    take_profits = completed_trades[completed_trades['åœåˆ©/åœæ'] == 'åœåˆ©'].shape[0]\n",
    "    stop_losses = total_trades - take_profits\n",
    "    win_rate = (take_profits / total_trades) * 100 if total_trades > 0 else 0\n",
    "\n",
    "    # --- 4. å»ºç«‹ç¸¾æ•ˆå ±å‘Š ---\n",
    "    summary_data = {\n",
    "        'é …ç›®': ['ç¸½äº¤æ˜“å¼µæ•¸', 'åœåˆ©æ¬¡æ•¸', 'åœææ¬¡æ•¸', 'å‹ç‡ (%)',\n",
    "                 'ç¸½æŠ•å…¥æˆæœ¬(å«è²»ç”¨)', 'ç¸½ç›ˆè™§ (å…ƒ)', 'ç¸½ç¸¾æ•ˆ (ROI %)'],\n",
    "        'æ•¸å€¼': [total_trades, take_profits, stop_losses, f\"{win_rate:.2f}\",\n",
    "                 f\"{total_investment_cost:,.0f} å…ƒ\", f\"{total_net_profit:,.0f} å…ƒ\", f\"{total_roi:.2f}\"]\n",
    "    }\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # å°‡çµæœå¯«å…¥ Excel\n",
    "    try:\n",
    "        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:\n",
    "            df.to_excel(writer, index=False, sheet_name='TradeLog')\n",
    "            df.update(completed_trades)\n",
    "            summary_df.to_excel(writer, sheet_name='TradeLog', startrow=0, startcol=14, index=False)\n",
    "        print(\"\\nç¸¾æ•ˆè¨ˆç®—å®Œæˆï¼\")\n",
    "    except Exception as e:\n",
    "        print(f\"éŒ¯èª¤ï¼šå¯«å…¥ Excel æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "\n",
    "def calculate_performance(data_dir):\n",
    "    \"\"\"\n",
    "    ç¸¾æ•ˆè¨ˆç®—\n",
    "    \"\"\"\n",
    "\n",
    "    # å–å¾—ä»Šå¤©çš„æ—¥æœŸ (ä¸å«æ™‚é–“)\n",
    "    today_dt00 = pd.to_datetime(datetime.now().date())\n",
    "\n",
    "    # ä½¿ç”¨æ—¥æ›†ï¼Œæ‰¾å‡ºè·é›¢ä»Šå¤©æœ€è¿‘çš„ã€Œå‰ä¸€å€‹äº¤æ˜“æ—¥ã€\n",
    "    #    schedule å‡½å¼æœƒå›å‚³ä¸€å€‹åŒ…å«æ‰€æœ‰äº¤æ˜“æ—¥çš„ DataFrame\n",
    "    #    æˆ‘å€‘å– end_date ç‚ºä»Šå¤©ï¼Œç„¶å¾Œæ‰¾å‡ºå€’æ•¸ç¬¬äºŒå€‹äº¤æ˜“æ—¥ï¼Œå°±æ˜¯å‰ä¸€å€‹äº¤æ˜“æ—¥\n",
    "    #    (å¦‚æœä»Šå¤©æœ¬èº«æ˜¯äº¤æ˜“æ—¥ï¼Œé‚£ä»Šå¤©çš„æ—¥æœŸæœƒæ˜¯æœ€å¾Œä¸€å€‹)\n",
    "    previous_trading_day = xtai_calendar.schedule(start_date=today_dt00 - timedelta(days=14), end_date=today_dt00).index[-2]\n",
    "    \n",
    "    # çµ„åˆå‡ºå‰ä¸€å€‹äº¤æ˜“æ—¥çš„æª”æ¡ˆè·¯å¾‘\n",
    "    previous_day_filename = f\"{previous_trading_day.strftime('%Y%m%d')}_æ¼²å¹….xlsx\"\n",
    "    \n",
    "    # å–å¾—æ—¥æœŸå­—ä¸²\n",
    "    day_str = previous_trading_day.strftime('%Y%m%d')\n",
    "\n",
    "    # åˆ¤æ–·è¦è®€å–å“ªå€‹æª”æ¡ˆ\n",
    "    # ğŸ’¡ æ³¨æ„ï¼šé€™è£¡å‡è¨­ä½ çš„ SL15 å‚™ä»½æª”æ˜¯ç‚ºäº†æ¸¬è©¦ -1.5% çš„ç¸¾æ•ˆ\n",
    "    if STOP_LOSS_PERCENT == -1.5:  \n",
    "        # -1.5%ï¼Œè®€ _15 æª”æ¡ˆ\n",
    "        previous_day_filename = f\"{day_str}_æ¼²å¹…_15.xlsx\"\n",
    "    else:\n",
    "        # -2.0%\n",
    "        previous_day_filename = f\"{day_str}_æ¼²å¹….xlsx\"\n",
    "\n",
    "    log_filepath = os.path.join(data_dir, previous_day_filename)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(log_filepath)\n",
    "        if any(col.startswith('Unnamed') for col in df.columns):\n",
    "            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "        if 'æç›Š%' not in df.columns: df['æç›Š%'] = pd.NA\n",
    "    except FileNotFoundError:\n",
    "        print(f\"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ˜¨å¤©çš„é¸è‚¡æª”æ¡ˆ '{log_filepath}'ã€‚\")\n",
    "        return\n",
    "    to_calculate_mask = df['æç›Š%'].isna()\n",
    "    if not to_calculate_mask.any():\n",
    "        print(\"æª”æ¡ˆä¸­æ‰€æœ‰è‚¡ç¥¨çš†å·²è¨ˆç®—éç¸¾æ•ˆã€‚\")\n",
    "        generate_summary_and_save(df, log_filepath)\n",
    "        return\n",
    "        \n",
    "    print(f\"æ‰¾åˆ° {to_calculate_mask.sum()} ç­†è‚¡ç¥¨éœ€è¦è¨ˆç®—ç¸¾æ•ˆ...\")\n",
    "\n",
    "    for index, row in df[to_calculate_mask].iterrows():\n",
    "        pnl_percent = 0\n",
    "        result = ''\n",
    "\n",
    "        stock_id = str(row['è‚¡ç¥¨ä»£è™Ÿ'])\n",
    "        purchase_price = row['ç•¶æ—¥æ”¶ç›¤åƒ¹']\n",
    "        \n",
    "        # yesterday_date_str = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "        backtest_result = run_high_precision_backtest(purchase_price, stock_id)\n",
    "        \n",
    "        # å¦‚æœå›æ¸¬æˆåŠŸï¼Œæ‰å¯«å…¥çµæœ\n",
    "        if result is not None and pnl_percent is not None:\n",
    "            df.loc[index, 'åœåˆ©/åœæ'] = result\n",
    "            df.loc[index, 'æç›Š%'] = round(pnl_percent, 2)\n",
    "\n",
    "        if backtest_result:\n",
    "            ohlc = backtest_result['daily_ohlc']\n",
    "                        \n",
    "            df.loc[index, 'éš”æ—¥é–‹ç›¤åƒ¹'] = ohlc['open']\n",
    "            df.loc[index, 'éš”æ—¥æœ€é«˜åƒ¹'] = ohlc['high']\n",
    "            df.loc[index, 'éš”æ—¥æœ€ä½åƒ¹'] = ohlc['low']\n",
    "            df.loc[index, 'éš”æ—¥æ”¶ç›¤åƒ¹'] = ohlc['close']\n",
    "            df.loc[index, 'è³£å‡ºåƒ¹æ ¼'] = round(backtest_result['sell_price'], 2)\n",
    "            df.loc[index, 'åœåˆ©/åœæ'] = backtest_result['result']\n",
    "            df.loc[index, 'æç›Š%'] = round(backtest_result['pnl_percent'], 2)\n",
    "\n",
    "    generate_summary_and_save(df, log_filepath)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"version : {__version__}\")\n",
    "\n",
    "    if not is_trading_day():\n",
    "        print(f\"ä»Šå¤©æ˜¯ {datetime.now().date().strftime('%Y-%m-%d')}ï¼Œéå°è‚¡äº¤æ˜“æ—¥ï¼Œç¨‹å¼çµæŸã€‚\")\n",
    "    else:\n",
    "        print(f\"ä»Šå¤©æ˜¯ {datetime.now().date().strftime('%Y-%m-%d')}ï¼Œå°è‚¡äº¤æ˜“æ—¥ï¼Œé–‹å§‹åŸ·è¡Œç¨‹å¼ã€‚\")\n",
    "\n",
    "        # --- ç™»å…¥ ---\n",
    "        try:\n",
    "            with open(config_path, 'r', encoding='utf-8') as f:\n",
    "                config = json.load(f)\n",
    "            \n",
    "            # å¾è¨­å®šæª”ä¸­å–å¾—ç™»å…¥è³‡è¨Š\n",
    "            fubon_config = config['fubon_api']\n",
    "            user_id = fubon_config['id']\n",
    "            user_password = fubon_config['password']\n",
    "            cert_path = fubon_config['cert_path']\n",
    "            cert_pass = fubon_config['cert_pass']\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(\"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° config.json è¨­å®šæª”ï¼\")\n",
    "            exit()\n",
    "        except KeyError:\n",
    "            print(\"éŒ¯èª¤ï¼šconfig.json æª”æ¡ˆä¸­çš„ key ä¸æ­£ç¢ºï¼\")\n",
    "            exit()\n",
    "\n",
    "        sdk = None\n",
    "        # é€£çµ API Server\n",
    "        sdk = FubonSDK()\n",
    "        # 2. åœ¨æ­¤è™•å¡«å…¥æ‚¨çš„ç™»å…¥è³‡è¨Š (è«‹åƒè€ƒå®˜æ–¹æ–‡ä»¶æˆ–æ‚¨çš„ .pfx æ†‘è­‰è¨­å®š)\n",
    "        accounts = sdk.login(user_id, user_password, cert_path, cert_pass)\n",
    "        print(\"Fubon SDK åˆå§‹åŒ–å®Œç•¢ï¼\")\n",
    "\n",
    "        sdk.init_realtime() # å»ºç«‹è¡Œæƒ…å…ƒä»¶é€£ç·š\n",
    "\n",
    "        # --- è³‡æ–™æŸ¥è©¢å€ ---\n",
    "        # å»ºç«‹è¡Œæƒ…æŸ¥è©¢ WebAPI é€£ç·š Object Instance\n",
    "        restStock = sdk.marketdata.rest_client.stock\n",
    "\n",
    "        calculate_performance(OUTPUT_DIRECTORY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d39cb",
   "metadata": {},
   "source": [
    "### è£½ä½œæ¦œå–® BY ä¸‰ç«¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de3edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# --- è¨­å®šå€ ---\n",
    "# Mitake åŒ¯å‡ºè³‡æ–™å¤¾çš„è·¯å¾‘\n",
    "DATA_DIRECTORY = r'E:\\è»Ÿé«”å€\\å…å®‰è£\\MitakeGU\\USER\\OUT'\n",
    "# æ¯æ—¥é¸è‚¡çµæœçš„å­˜æª”è³‡æ–™å¤¾åç¨±\n",
    "OUTPUT_DIRECTORY = 'out_oneNight'\n",
    "# --- è¨­å®šçµæŸ ---\n",
    "\n",
    "def select_stocks(csv_filepath):\n",
    "    \"\"\"å¾çµ¦å®šçš„ CSV æª”æ¡ˆä¸­ï¼Œæ ¹æ“šç‰¹å®šæ¢ä»¶ç¯©é¸è‚¡ç¥¨ã€‚\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_filepath, skiprows=2, encoding='utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"éŒ¯èª¤ï¼šåœ¨æŒ‡å®šè·¯å¾‘ä¸‹æ‰¾ä¸åˆ°æª”æ¡ˆ -> {csv_filepath}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"è®€å–æª”æ¡ˆæ™‚ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # è³‡æ–™æ¸…ç†èˆ‡ç¯©é¸ (ç¶­æŒä¸è®Š)\n",
    "    df['åç¨±'] = df['åç¨±'].str.strip()\n",
    "    numeric_cols = ['å¹…åº¦ï¼…', 'æˆäº¤é‡', 'æˆäº¤']\n",
    "    for col in numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df.dropna(subset=numeric_cols, inplace=True)\n",
    "\n",
    "    condition_gain = df['å¹…åº¦ï¼…'] >= 5\n",
    "    condition_volume = df['æˆäº¤é‡'] >= 1500\n",
    "    condition_value = (df['æˆäº¤é‡'] * 1000) * df['æˆäº¤'] >= 90000000\n",
    "    condition_exclude = ~df['ç”¢æ¥­åˆ¥'].str.contains(\"ETF|å…¬å¸å‚µ\", na=False)\n",
    "    selected_df = df[condition_gain & condition_volume & condition_exclude & condition_value].copy()\n",
    "    return selected_df\n",
    "\n",
    "def save_daily_selection(selected_stocks, output_dir):\n",
    "    \"\"\"å°‡ç¯©é¸å‡ºä¾†çš„è‚¡ç¥¨å­˜æˆæ¯æ—¥ç¨ç«‹çš„ Excel æª”æ¡ˆã€‚\"\"\"\n",
    "    if selected_stocks.empty:\n",
    "        print(\"ä»Šæ—¥æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ã€‚\")\n",
    "        return\n",
    "\n",
    "    # 1. æª¢æŸ¥ä¸¦å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"å»ºç«‹æ–°è³‡æ–™å¤¾: {output_dir}\")\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    now = datetime.now()\n",
    "    # 2. æº–å‚™è¦å¯«å…¥çš„è³‡æ–™æ¬„ä½\n",
    "    today_str_ymd = now.strftime('%Y-%m-%d')\n",
    "    output_df = pd.DataFrame({\n",
    "        'é¸è‚¡æ—¥': today_str_ymd,\n",
    "        'è‚¡ç¥¨ä»£è™Ÿ': selected_stocks['è‚¡è™Ÿ'].astype(int),\n",
    "        'è‚¡ç¥¨åç¨±': selected_stocks['åç¨±'],\n",
    "        'ç•¶æ—¥æ”¶ç›¤åƒ¹': selected_stocks['æˆäº¤'],\n",
    "        'ç•¶æ—¥æ¼²å¹…%': selected_stocks['å¹…åº¦ï¼…'],\n",
    "        'éš”æ—¥é–‹ç›¤åƒ¹': '', # é ç•™æ¬„ä½\n",
    "        'éš”æ—¥æœ€é«˜åƒ¹': '', # é ç•™æ¬„ä½\n",
    "        'éš”æ—¥æœ€ä½åƒ¹': '', # é ç•™æ¬„ä½\n",
    "        'éš”æ—¥æ”¶ç›¤åƒ¹': '', # é ç•™æ¬„ä½\n",
    "        'è³£å‡ºåƒ¹æ ¼': '',\n",
    "        'åœåˆ©/åœæ': '',\n",
    "        'æç›Š%': ''\n",
    "    })\n",
    "    \n",
    "    # å¦‚æœåœ¨ä¸‹åˆ 1:30 ä¹‹å‰åŸ·è¡Œï¼Œå‰‡åŠ ä¸Š \"_ä¸­åˆ\"\n",
    "    today_str_filename = now.strftime('%Y%m%d')\n",
    "    if now.hour <= 13 and now.minute <= 30:\n",
    "        output_filename = f\"{today_str_filename}_æ¼²å¹…_ä¸­åˆ.xlsx\"\n",
    "    else:\n",
    "        output_filename = f\"{today_str_filename}_æ¼²å¹….xlsx\"\n",
    "        \n",
    "        # 2. å‚™ä»½æª”æ¡ˆï¼šç”¨æ–¼è¨ˆç®— -1.5% åœæçš„å°ˆå±¬ exe\n",
    "        output_filename_15 = f\"{today_str_filename}_æ¼²å¹…_15.xlsx\"\n",
    "        output_filepath_15 = os.path.join(output_dir, output_filename_15)\n",
    "        output_df.to_excel(output_filepath_15, index=False)\n",
    "    output_filepath = os.path.join(output_dir, output_filename)\n",
    "    output_df.to_excel(output_filepath, index=False)\n",
    "    print(f\"æ¦œå–®å·²å„²å­˜è‡³: {output_filepath}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # çµ„åˆå‡ºä»Šå¤© Mitake çš„ CSV æª”æ¡ˆè·¯å¾‘\n",
    "    today_str = datetime.now().strftime('%Y%m%d')\n",
    "    csv_filename = f\"{today_str}_æ¼²å¹…æ’è¡Œ.csv\"\n",
    "    csv_filepath = os.path.join(DATA_DIRECTORY, csv_filename)\n",
    "    \n",
    "    print(f\"æ­£åœ¨è®€å–æª”æ¡ˆ: {csv_filepath}\")\n",
    "    \n",
    "    # åŸ·è¡Œé¸è‚¡\n",
    "    selected_stocks_today = select_stocks(csv_filepath)\n",
    "    \n",
    "    # å„²å­˜çµæœ\n",
    "    save_daily_selection(selected_stocks_today, OUTPUT_DIRECTORY)\n",
    "    \n",
    "    # if not selected_stocks_today.empty:\n",
    "    #     print(\"\\n--- ä»Šæ—¥é¸è‚¡çµæœ ---\")\n",
    "    #     display_cols = ['è‚¡è™Ÿ', 'åç¨±', 'ç”¢æ¥­åˆ¥', 'æˆäº¤', 'å¹…åº¦ï¼…', 'æˆäº¤é‡']\n",
    "    #     print(selected_stocks_today[display_cols].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fubon_venv (3.8.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
